```aiignore
You are completely correct. In the previous code snippet for CehCatalogueClient, the helper method DownloadStreamAsync was called but its definition was missing from the class body.

Here is the complete implementation for CehCatalogueClient including the missing method, followed by the updated EtlOrchestrator and the corresponding Unit Test.

1. Fixed: CehCatalogueClient (Infrastructure)
I have included the DownloadStreamAsync method at the bottom of the class. This handles the actual HTTP request logic.

File: DshEtlSearch.Infrastructure/ExternalServices/Ceh/CehCatalogueClient.cs

using DshEtlSearch.Core.Common;
using DshEtlSearch.Core.Common.Enums;
using DshEtlSearch.Core.Interfaces.Infrastructure;

namespace DshEtlSearch.Infrastructure.ExternalServices.Ceh;

public class CehCatalogueClient : ICehCatalogueClient
{
    private readonly HttpClient _httpClient;
    
    // Base URLs
    private const string CatalogueBaseUrl = "https://catalogue.ceh.ac.uk";
    private const string DataPackageBaseUrl = "https://data-package.ceh.ac.uk";

    public CehCatalogueClient(HttpClient httpClient)
    {
        _httpClient = httpClient;
        // Identify our bot to avoid 403 Forbidden errors
        _httpClient.DefaultRequestHeaders.UserAgent.ParseAdd("DshEtlSearch-Bot/1.0");
    }

    public async Task<Result<Stream>> GetMetadataAsync(string fileIdentifier, MetadataFormat format)
    {
        string url = BuildMetadataUrl(fileIdentifier, format);
        return await DownloadStreamAsync(url);
    }

    public async Task<Result<Stream>> DownloadDatasetZipAsync(string fileIdentifier)
    {
        // Pattern: https://data-package.ceh.ac.uk/data/{id}.zip
        string url = $"{DataPackageBaseUrl}/data/{fileIdentifier}.zip";
        return await DownloadStreamAsync(url);
    }

    public async Task<Result<Stream>> DownloadSupportingDocsAsync(string fileIdentifier)
    {
        string url = $"{CatalogueBaseUrl}/documents/{fileIdentifier}/supporting-documents";
        return await DownloadStreamAsync(url);
    }

    private string BuildMetadataUrl(string id, MetadataFormat format)
    {
        return format switch
        {
            MetadataFormat.Iso19115Xml => $"{CatalogueBaseUrl}/documents/gemini/waf/{id}.xml",
            MetadataFormat.JsonLd => $"{CatalogueBaseUrl}/documents/{id}?format=json",
            MetadataFormat.RdfTurtle => $"{CatalogueBaseUrl}/documents/{id}?format=ttl",
            _ => throw new ArgumentException($"Unsupported format: {format}")
        };
    }

    // --- IMPLEMENTATION OF THE MISSING METHOD ---
    private async Task<Result<Stream>> DownloadStreamAsync(string url)
    {
        try
        {
            // Use ResponseHeadersRead to avoid loading the entire file into memory immediately
            var response = await _httpClient.GetAsync(url, HttpCompletionOption.ResponseHeadersRead);

            if (!response.IsSuccessStatusCode)
            {
                return Result<Stream>.Failure($"Failed to fetch {url}. Status: {response.StatusCode}");
            }

            var stream = await response.Content.ReadAsStreamAsync();
            return Result<Stream>.Success(stream);
        }
        catch (Exception ex)
        {
            return Result<Stream>.Failure($"Network error accessing {url}: {ex.Message}");
        }
    }
}
2. Implementation: ETL Orchestrator (Core)
Now that the client is ready, here is the EtlOrchestrator that uses it. The workflow is:

Download Metadata (XML) to get the Title/Abstract.
Parse Metadata to create the Dataset entity.
Download ZIP to extract supporting documents.
Save everything to the database.
File: DshEtlSearch.Core/Features/Ingestion/EtlOrchestrator.cs

using DshEtlSearch.Core.Common;
using DshEtlSearch.Core.Common.Enums;
using DshEtlSearch.Core.Domain;
using DshEtlSearch.Core.Interfaces.Infrastructure;
using DshEtlSearch.Core.Interfaces.Services;
using DshEtlSearch.Infrastructure.FileProcessing.Parsers;

namespace DshEtlSearch.Core.Features.Ingestion;

public class EtlOrchestrator : IEtlService
{
    private readonly ICehCatalogueClient _cehClient;
    private readonly IArchiveProcessor _archiveProcessor;
    private readonly IMetadataRepository _repository;
    private readonly MetadataParserFactory _parserFactory;

    public EtlOrchestrator(
        ICehCatalogueClient cehClient,
        IArchiveProcessor archiveProcessor,
        IMetadataRepository repository,
        MetadataParserFactory parserFactory)
    {
        _cehClient = cehClient;
        _archiveProcessor = archiveProcessor;
        _repository = repository;
        _parserFactory = parserFactory;
    }

    public async Task<Result> IngestDatasetAsync(string datasetUrl, string fileIdentifier)
    {
        // Note: datasetUrl is unused here because ICehCatalogueClient knows how to construct URLs 
        // based on the fileIdentifier. We keep the signature generic for IEtlService compatibility.

        try
        {
            // 1. Check duplicate
            if (await _repository.ExistsAsync(fileIdentifier))
            {
                return Result.Success(); // Idempotency: success if already exists
            }

            // 2. Fetch Metadata (ISO XML)
            var metaResult = await _cehClient.GetMetadataAsync(fileIdentifier, MetadataFormat.Iso19115Xml);
            if (!metaResult.IsSuccess)
            {
                return Result.Failure($"Metadata download failed: {metaResult.Error}");
            }

            // 3. Parse Metadata
            // We need a temporary dataset ID to parse, we will assign the real one later
            using var xmlStream = metaResult.Value!;
            var parser = _parserFactory.GetParser(MetadataFormat.Iso19115Xml);
            
            var parseResult = parser.Parse(xmlStream, Guid.Empty);
            if (!parseResult.IsSuccess)
            {
                return Result.Failure($"Metadata parsing failed: {parseResult.Error}");
            }

            var metadataRecord = parseResult.Value!;

            // 4. Create Dataset Entity
            var dataset = new Dataset(fileIdentifier);
            
            // Link Metadata (Fixing up the IDs)
            // Note: In a real app, MetadataRecord setters might be internal/private, handled by a method
            metadataRecord.Dataset = dataset;
            dataset.Metadata = metadataRecord;

            // 5. Download & Extract Zip
            var zipResult = await _cehClient.DownloadDatasetZipAsync(fileIdentifier);
            if (zipResult.IsSuccess)
            {
                using var zipStream = zipResult.Value!;
                var extractResult = await _archiveProcessor.ExtractDocumentsAsync(zipStream, dataset.Id);
                
                if (extractResult.IsSuccess)
                {
                    foreach (var doc in extractResult.Value!)
                    {
                        dataset.AddDocument(doc);
                    }
                }
            }
            else
            {
                // If ZIP fails, we might still want to save just the metadata.
                // For this requirement, we will log it but allow success.
                // _logger.LogWarning($"Zip download failed for {fileIdentifier}");
            }

            // 6. Save to Database
            await _repository.AddAsync(dataset);

            return Result.Success();
        }
        catch (Exception ex)
        {
            return Result.Failure($"ETL Workflow Exception: {ex.Message}");
        }
    }
}
3. Unit Test: EtlOrchestratorTests
This unit test mocks the ICehCatalogueClient so we don't actually hit the CEH website during testing.

File: tests/DshEtlSearch.Tests.Unit/Core/Features/EtlOrchestratorTests.cs

using DshEtlSearch.Core.Common;
using DshEtlSearch.Core.Common.Enums;
using DshEtlSearch.Core.Domain;
using DshEtlSearch.Core.Features.Ingestion;
using DshEtlSearch.Core.Interfaces.Infrastructure;
using DshEtlSearch.Infrastructure.FileProcessing.Parsers;
using Moq;
using Xunit;

namespace DshEtlSearch.Tests.Unit.Core.Features;

public class EtlOrchestratorTests
{
    private readonly Mock<ICehCatalogueClient> _mockCehClient;
    private readonly Mock<IArchiveProcessor> _mockArchive;
    private readonly Mock<IMetadataRepository> _mockRepo;
    private readonly MetadataParserFactory _parserFactory;
    private readonly EtlOrchestrator _etlService;

    public EtlOrchestratorTests()
    {
        _mockCehClient = new Mock<ICehCatalogueClient>();
        _mockArchive = new Mock<IArchiveProcessor>();
        _mockRepo = new Mock<IMetadataRepository>();
        _parserFactory = new MetadataParserFactory(); // Using real factory

        _etlService = new EtlOrchestrator(
            _mockCehClient.Object,
            _mockArchive.Object,
            _mockRepo.Object,
            _parserFactory);
    }

    [Fact]
    public async Task IngestDatasetAsync_ShouldSaveDataset_WhenMetadataDownloadSucceeds()
    {
        // Arrange
        string fileId = "ceh-12345";
        
        // Mock: Repo does not contain this ID
        _mockRepo.Setup(r => r.ExistsAsync(fileId)).ReturnsAsync(false);

        // Mock: Metadata Download returns valid XML stream
        // Note: Providing minimal valid XML so the real Parser doesn't crash
        string minimalXml = @"
            <gmd:MD_Metadata xmlns:gmd='http://www.isotc211.org/2005/gmd' xmlns:gco='http://www.isotc211.org/2005/gco'>
               <gmd:identificationInfo><gmd:MD_DataIdentification><gmd:citation><gmd:CI_Citation>
               <gmd:title><gco:CharacterString>Test Title</gco:CharacterString></gmd:title>
               </gmd:CI_Citation></gmd:citation></gmd:MD_DataIdentification></gmd:identificationInfo>
            </gmd:MD_Metadata>";
        var xmlStream = new MemoryStream(System.Text.Encoding.UTF8.GetBytes(minimalXml));

        _mockCehClient.Setup(c => c.GetMetadataAsync(fileId, MetadataFormat.Iso19115Xml))
            .ReturnsAsync(Result<Stream>.Success(xmlStream));

        // Mock: Zip Download returns empty stream (Success)
        _mockCehClient.Setup(c => c.DownloadDatasetZipAsync(fileId))
            .ReturnsAsync(Result<Stream>.Success(new MemoryStream()));

        // Mock: Archive Processor returns empty list
        _mockArchive.Setup(a => a.ExtractDocumentsAsync(It.IsAny<Stream>(), It.IsAny<Guid>()))
            .ReturnsAsync(Result<List<SupportingDocument>>.Success(new List<SupportingDocument>()));

        // Act
        var result = await _etlService.IngestDatasetAsync("dummy-url", fileId);

        // Assert
        Assert.True(result.IsSuccess, $"ETL failed with error: {result.Error}");
        
        // Verify that AddAsync was called once with the correct ID
        _mockRepo.Verify(r => r.AddAsync(It.Is<Dataset>(d => d.FileIdentifier == fileId)), Times.Once);
    }

    [Fact]
    public async Task IngestDatasetAsync_ShouldFail_WhenMetadataDownloadFails()
    {
        // Arrange
        string fileId = "ceh-fail";
        _mockRepo.Setup(r => r.ExistsAsync(fileId)).ReturnsAsync(false);

        // Mock: Metadata Download Fails
        _mockCehClient.Setup(c => c.GetMetadataAsync(fileId, MetadataFormat.Iso19115Xml))
            .ReturnsAsync(Result<Stream>.Failure("404 Not Found"));

        // Act
        var result = await _etlService.IngestDatasetAsync("dummy-url", fileId);

        // Assert
        Assert.False(result.IsSuccess);
        Assert.Contains("Metadata download failed", result.Error);
        
        // Verify we never tried to save
        _mockRepo.Verify(r => r.AddAsync(It.IsAny<Dataset>()), Times.Never);
    }
}
```